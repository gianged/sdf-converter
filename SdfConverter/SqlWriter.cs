using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Text;

using SdfConverter.Models;

namespace SdfConverter;

/// <summary>
/// Generates PostgreSQL-compatible SQL files from attendance records.
/// Outputs batched INSERT statements with ON CONFLICT DO NOTHING for duplicates.
/// </summary>
public sealed class SqlWriter
{
    /// <summary>
    /// Default number of records per INSERT batch.
    /// </summary>
    public const int DefaultBatchSize = 1000;

    /// <summary>
    /// Source value for migrated records.
    /// </summary>
    private const string MigrationSource = "sdf_migration";

    private readonly string _schemaName;

    /// <summary>
    /// Creates a SqlWriter for the specified PostgreSQL schema.
    /// </summary>
    /// <param name="schemaName">PostgreSQL schema name (e.g., public, hr)</param>
    /// <exception cref="ArgumentException">If schemaName is null, empty, or invalid</exception>
    public SqlWriter(string schemaName = "public")
    {
        if (string.IsNullOrWhiteSpace(schemaName))
        {
            throw new ArgumentException("Schema name cannot be null or empty.", nameof(schemaName));
        }

        _schemaName = schemaName;
    }

    /// <summary>
    /// PostgreSQL schema name for generated SQL statements.
    /// </summary>
    public string SchemaName => _schemaName;

    /// <summary>
    /// Writes attendance records to a PostgreSQL-compatible SQL file.
    /// Records are batched into multiple INSERT statements for performance.
    /// </summary>
    /// <param name="outputPath">Path to output .sql file</param>
    /// <param name="records">Attendance records to write</param>
    /// <param name="metadata">Source file metadata for header comments</param>
    /// <param name="progress">Optional progress reporter (reports records written)</param>
    /// <returns>Export result with record count, file size, and batch count</returns>
    /// <exception cref="ArgumentException">If outputPath is null or empty</exception>
    /// <exception cref="ArgumentNullException">If records or metadata is null</exception>
    /// <exception cref="IOException">If file write fails</exception>
    public ExportResult WriteToFile(
        string outputPath,
        IReadOnlyList<AttendanceRecord> records,
        SourceMetadata metadata,
        IProgress<int>? progress = null)
    {
        if (string.IsNullOrWhiteSpace(outputPath))
        {
            throw new ArgumentException("Output path cannot be null or empty.", nameof(outputPath));
        }

        if (records == null)
        {
            throw new ArgumentNullException(nameof(records));
        }

        if (metadata == null)
        {
            throw new ArgumentNullException(nameof(metadata));
        }

        var recordsWritten = 0;
        var batchCount = 0;

        try
        {
            using var writer = new StreamWriter(outputPath, false, Encoding.UTF8, bufferSize: 65536);

            // Write header comment
            WriteHeader(writer, metadata);

            // Write batched INSERT statements
            for (var i = 0; i < records.Count; i += DefaultBatchSize)
            {
                var batchEnd = Math.Min(i + DefaultBatchSize, records.Count);
                var batchRecords = new List<AttendanceRecord>(batchEnd - i);

                for (var j = i; j < batchEnd; j++)
                {
                    batchRecords.Add(records[j]);
                }

                if (batchRecords.Count > 0)
                {
                    WriteInsertBatch(writer, batchRecords);
                    recordsWritten += batchRecords.Count;
                    batchCount++;

                    progress?.Report(recordsWritten);
                }
            }

            // Final progress report
            progress?.Report(recordsWritten);
        }
        catch (IOException ex)
        {
            throw new IOException($"Failed to write SQL file to '{outputPath}': {ex.Message}", ex);
        }

        // Get file size
        var fileInfo = new FileInfo(outputPath);
        var fileSizeBytes = fileInfo.Exists ? fileInfo.Length : 0;

        return new ExportResult(recordsWritten, fileSizeBytes, batchCount);
    }

    /// <summary>
    /// Writes the SQL file header with metadata comments.
    /// </summary>
    /// <param name="writer">StreamWriter to write to</param>
    /// <param name="metadata">Source metadata for header</param>
    public void WriteHeader(StreamWriter writer, SourceMetadata metadata)
    {
        writer.WriteLine("-- Generated by SdfConverter");
        writer.WriteLine($"-- Source: {metadata.SdfFileName}");
        writer.WriteLine($"-- Table: {metadata.TableName}");
        writer.WriteLine($"-- Records: {metadata.RecordCount:N0}");
        writer.WriteLine($"-- Generated: {DateTimeOffset.Now:yyyy-MM-ddTHH:mm:sszzz}");
        writer.WriteLine();
    }

    /// <summary>
    /// Writes a single batched INSERT statement for multiple records.
    /// </summary>
    private void WriteInsertBatch(StreamWriter writer, IReadOnlyList<AttendanceRecord> records)
    {
        writer.WriteLine($"INSERT INTO {_schemaName}.attendance (device_uid, timestamp, verify_type, source)");
        writer.WriteLine("VALUES");

        for (var i = 0; i < records.Count; i++)
        {
            var record = records[i];
            var timestamp = FormatTimestamp(record.Timestamp);
            var isLast = i == records.Count - 1;
            var separator = isLast ? "" : ",";

            writer.WriteLine($"  ({record.DeviceUid}, '{timestamp}', {record.VerifyType}, '{MigrationSource}'){separator}");
        }

        writer.WriteLine("ON CONFLICT (device_uid, timestamp) DO NOTHING;");
        writer.WriteLine();
    }

    /// <summary>
    /// Formats a DateTimeOffset as PostgreSQL-compatible timestamp with timezone.
    /// </summary>
    private static string FormatTimestamp(DateTimeOffset timestamp)
    {
        // Format: 2024-01-15 08:30:00+07
        return timestamp.ToString("yyyy-MM-dd HH:mm:sszzz");
    }

    /// <summary>
    /// Writes dynamic records to a PostgreSQL-compatible SQL file.
    /// Exports all columns as-is without predefined mappings.
    /// </summary>
    /// <param name="outputPath">Path to output .sql file</param>
    /// <param name="records">Dynamic records to write</param>
    /// <param name="schema">Table schema with column metadata</param>
    /// <param name="metadata">Source file metadata for header comments</param>
    /// <param name="progress">Optional progress reporter</param>
    /// <returns>Export result with record count, file size, and batch count</returns>
    public ExportResult WriteDynamicToFile(
        string outputPath,
        IReadOnlyList<DynamicRecord> records,
        TableSchema schema,
        SourceMetadata metadata,
        IProgress<int>? progress = null)
    {
        if (string.IsNullOrWhiteSpace(outputPath))
        {
            throw new ArgumentException("Output path cannot be null or empty.", nameof(outputPath));
        }

        if (records == null)
        {
            throw new ArgumentNullException(nameof(records));
        }

        if (schema == null)
        {
            throw new ArgumentNullException(nameof(schema));
        }

        if (metadata == null)
        {
            throw new ArgumentNullException(nameof(metadata));
        }

        var recordsWritten = 0;
        var batchCount = 0;

        try
        {
            using var writer = new StreamWriter(outputPath, false, Encoding.UTF8, bufferSize: 65536);

            // Write header comment
            WriteHeader(writer, metadata);

            // Write batched INSERT statements
            for (var i = 0; i < records.Count; i += DefaultBatchSize)
            {
                var batchEnd = Math.Min(i + DefaultBatchSize, records.Count);
                var batchRecords = new List<DynamicRecord>(batchEnd - i);

                for (var j = i; j < batchEnd; j++)
                {
                    batchRecords.Add(records[j]);
                }

                if (batchRecords.Count > 0)
                {
                    WriteDynamicBatch(writer, batchRecords, schema);
                    recordsWritten += batchRecords.Count;
                    batchCount++;

                    progress?.Report(recordsWritten);
                }
            }

            // Final progress report
            progress?.Report(recordsWritten);
        }
        catch (IOException ex)
        {
            throw new IOException($"Failed to write SQL file to '{outputPath}': {ex.Message}", ex);
        }

        // Get file size
        var fileInfo = new FileInfo(outputPath);
        var fileSizeBytes = fileInfo.Exists ? fileInfo.Length : 0;

        return new ExportResult(recordsWritten, fileSizeBytes, batchCount);
    }

    /// <summary>
    /// Writes a single batched INSERT statement for dynamic records.
    /// Used for streaming export to write batches directly without holding all records in memory.
    /// </summary>
    /// <param name="writer">StreamWriter to write to</param>
    /// <param name="records">Batch of records to write</param>
    /// <param name="schema">Table schema with column metadata</param>
    public void WriteDynamicBatch(StreamWriter writer, IReadOnlyList<DynamicRecord> records, TableSchema schema)
    {
        // Build column list
        var columnNames = string.Join(", ", schema.Columns.Select(c => $"[{c.ColumnName}]"));
        writer.WriteLine($"INSERT INTO {_schemaName}.[{schema.TableName}] ({columnNames})");
        writer.WriteLine("VALUES");

        for (var i = 0; i < records.Count; i++)
        {
            var record = records[i];
            var values = new List<string>();

            foreach (var column in schema.Columns)
            {
                if (record.Values.TryGetValue(column.ColumnName, out var value))
                {
                    values.Add(FormatValue(value, column.DataType));
                }
                else
                {
                    values.Add("NULL");
                }
            }

            var isLast = i == records.Count - 1;
            var separator = isLast ? "" : ",";
            writer.WriteLine($"  ({string.Join(", ", values)}){separator}");
        }

        writer.WriteLine(";");
        writer.WriteLine();
    }

    /// <summary>
    /// Formats a value for SQL output based on the column data type.
    /// </summary>
    /// <param name="value">Value to format (null for NULL)</param>
    /// <param name="dataType">SQL Server CE data type</param>
    /// <returns>Formatted SQL value string</returns>
    private static string FormatValue(object? value, string dataType)
    {
        if (value == null || value == DBNull.Value)
        {
            return "NULL";
        }

        var lowerType = dataType.ToLowerInvariant();

        // Numeric types - output as-is
        if (lowerType is "int" or "bigint" or "smallint" or "tinyint" or "float" or "real" or "money" or "numeric" or "decimal")
        {
            return Convert.ToString(value, System.Globalization.CultureInfo.InvariantCulture) ?? "NULL";
        }

        // Boolean type
        if (lowerType == "bit")
        {
            return Convert.ToBoolean(value) ? "true" : "false";
        }

        // Date/time types
        if (lowerType == "datetime")
        {
            if (value is DateTime dt)
            {
                return $"'{dt:yyyy-MM-dd HH:mm:ss}'";
            }
            return $"'{value}'";
        }

        // Binary types - output as hex
        if (lowerType is "image" or "binary" or "varbinary")
        {
            if (value is byte[] bytes)
            {
                var hex = BitConverter.ToString(bytes).Replace("-", "");
                return $"'\\x{hex}'";
            }
            return "NULL";
        }

        // GUID type
        if (lowerType == "uniqueidentifier")
        {
            return $"'{value}'";
        }

        // String types - escape single quotes
        var stringValue = value.ToString() ?? "";
        var escaped = stringValue.Replace("'", "''");
        return $"'{escaped}'";
    }
}
