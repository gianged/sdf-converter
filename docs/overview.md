# SDF Converter - Project Overview

## Project Goal

One-time tool to extract historical attendance data from SQL Server Compact Edition (`.sdf`) files and export to a PostgreSQL-compatible `.sql` file.

---

## Workflow

```
SDF file  -->  SdfConverter  -->  output.sql  -->  psql  -->  PostgreSQL
```

---

## Why C#?

SQL Server CE libraries only exist for .NET. There are no viable Rust, Node.js, or Python libraries that can read `.sdf` files. C# is the only practical choice.

---

## Source Data

### SDF File

- **Format**: SQL Server Compact Edition 4.0
- **Origin**: TAS ERP system backup
- **Contains**: Historical attendance records

### Expected Schema (may vary)

Common table names: `CHECKINOUT`, `att_log`, `attendance`, `T_LOG`

| Column     | Type     | Description            |
| ---------- | -------- | ---------------------- |
| USERID     | int      | Employee ID            |
| CHECKTIME  | datetime | Check-in/out timestamp |
| VERIFYCODE | int      | Verification method    |
| SENSORID   | int      | Device ID (optional)   |

---

## Target Schema

Same PostgreSQL schema as the main zk-attendance application:

```sql
CREATE TABLE attendance (
    id SERIAL PRIMARY KEY,
    device_uid INTEGER NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL,
    verify_type SMALLINT NOT NULL,
    status SMALLINT NOT NULL DEFAULT 0,
    source VARCHAR(20) NOT NULL DEFAULT 'device',
    created_at TIMESTAMPTZ DEFAULT NOW(),

    CONSTRAINT uq_attendance_record UNIQUE (device_uid, timestamp)
);
```

Records from this tool will have `source = 'sdf_migration'`.

---

## CLI Interface

```
SdfConverter.exe <sdf-file> [options]

Arguments:
  sdf-file                    Path to .sdf file

Options:
  --output, -o <path>         Output .sql file path (default: same as input with .sql extension)
  --table <name>              Specify attendance table name (auto-detect if not provided)
  --schema <name>             PostgreSQL schema name (default: public)
  --verbose                   Show detailed progress
```

### Examples

```bash
# Auto-detect table, default output
SdfConverter.exe "C:\backup\attendance.sdf"
# Output: attendance.sql

# Specify output file
SdfConverter.exe "C:\backup\attendance.sdf" -o "C:\output\migration.sql"

# Specify table name
SdfConverter.exe "C:\backup\data.sdf" --table CHECKINOUT --verbose

# Specify custom PostgreSQL schema
SdfConverter.exe "C:\backup\data.sdf" --schema hr -o migration.sql
```

---

## Output

### Discovery Phase (verbose)

```
Opening SDF file: C:\backup\attendance.sdf
Found 12 tables:
  - CHECKINOUT (45,230 rows)
  - EMPLOYEES (156 rows)
  - DEPARTMENTS (8 rows)
  ...

Auto-selected table: CHECKINOUT
Columns: USERID (int), CHECKTIME (datetime), VERIFYCODE (int), SENSORID (int)
```

### Export Phase

```
Exporting to: attendance.sql
  [10000/45230] 22.1%
  [20000/45230] 44.2%
  ...

Export complete:
  Total records: 45,230
  Output file: attendance.sql (2.3 MB)
```

### Generated SQL File

```sql
-- Generated by SdfConverter
-- Source: attendance.sdf
-- Table: CHECKINOUT
-- Schema: hr
-- Records: 45,230
-- Generated: 2024-01-15T10:30:00

INSERT INTO hr.attendance (device_uid, timestamp, verify_type, source)
VALUES
  (123, '2024-01-15 08:30:00+07', 1, 'sdf_migration'),
  (124, '2024-01-15 08:31:00+07', 1, 'sdf_migration')
ON CONFLICT (device_uid, timestamp) DO NOTHING;

-- (batched inserts continue...)
```

Note: `hr.attendance` uses the `--schema` value (defaults to `public`)

---

## Project Structure

```
SdfConverter/
├── SdfConverter.csproj
├── Program.cs
├── SdfReader.cs          # SDF file operations
├── SqlWriter.cs          # SQL file generation
├── SchemaDiscovery.cs    # Table/column detection
└── Models/
    ├── AttendanceRecord.cs
    └── ExportResult.cs
```

---

## Dependencies

```xml
<Project Sdk="Microsoft.NET.Sdk">
  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net8.0</TargetFramework>
    <PublishSingleFile>true</PublishSingleFile>
    <SelfContained>true</SelfContained>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="EntityFramework.SqlServerCompact" Version="6.5.1" />
    <PackageReference Include="System.CommandLine" Version="2.0.0" />
  </ItemGroup>
</Project>
```

---

## Build & Distribution

### Build

```bash
dotnet publish -c Release -r win-x64 --self-contained
```

### Output

Single executable: `SdfConverter.exe` (~60-80 MB, self-contained)

Or smaller if .NET 8 runtime is installed:

```bash
dotnet publish -c Release
# Output: ~2 MB, requires .NET 8 runtime
```

---

## Error Handling

| Error                     | Handling                                   |
| ------------------------- | ------------------------------------------ |
| SDF file not found        | Exit with clear error message              |
| SDF file locked           | Suggest closing TAS ERP                    |
| No attendance table found | List available tables, ask user to specify |
| Cannot write output file  | Show permission/path error                 |
| Invalid data format       | Log warning, skip record, continue         |

---

## Column Mapping

The tool handles various column naming conventions:

| SDF Column                                      | PostgreSQL Column |
| ----------------------------------------------- | ----------------- |
| USERID, UserID, user_id, EmpID                  | device_uid        |
| CHECKTIME, CheckTime, check_time, LogTime       | timestamp         |
| VERIFYCODE, VerifyCode, verify_code, VerifyType | verify_type       |
| SENSORID, SensorID, DeviceID                    | (ignored)         |

---

## Usage with PostgreSQL

After generating the SQL file, import it:

```bash
psql -h localhost -U postgres -d attendance -f attendance.sql
```

---

## Notes

- This is a one-time export tool, not meant for ongoing sync
- Run this BEFORE starting regular sync with zk-attendance
- Duplicates are handled automatically via `ON CONFLICT DO NOTHING`
- Source field distinguishes migrated data from device data
